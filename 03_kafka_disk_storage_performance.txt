================================================================================
                    WHY KAFKA'S DISK STORAGE IS FAST
================================================================================

Kafka achieves high throughput despite using disk storage. Here's how:

================================================================================
1. SEQUENTIAL I/O (Append-Only, No Random Seeks)
================================================================================

RANDOM I/O (Traditional databases):
    - Disk head moves to different locations to read/write
    - Each seek takes ~10ms on HDD
    - Like reading a book by jumping to random pages

    Disk: [______|______|______|______]
              ^      ^      ^
              |      |      |
           seek1  seek2  seek3  (slow, head moves around)

SEQUENTIAL I/O (Kafka):
    - Always write to end of file (append-only)
    - Always read in order
    - No seeking, continuous read/write
    - Like reading a book from start to end

    Disk: [data1|data2|data3|data4|data5|-->
           =================================>
           continuous read/write (fast)

PERFORMANCE COMPARISON:
    +------------------+------------+-------------+
    |    Operation     |    HDD     |     SSD     |
    +------------------+------------+-------------+
    | Random I/O       | ~100 IOPS  | ~10K IOPS   |
    | Sequential I/O   | ~100 MB/s  | ~500 MB/s   |
    +------------------+------------+-------------+

    Sequential I/O on HDD can be faster than Random I/O on SSD!

WHY KAFKA USES APPEND-ONLY:
    - Messages are immutable (never modified)
    - New messages always added at end
    - Old messages deleted by removing entire segment files
    - No in-place updates = no random seeks

    Kafka Log Structure:

    Partition 0/
    ├── 00000000000000000000.log  (segment 1: offsets 0-999)
    ├── 00000000000000001000.log  (segment 2: offsets 1000-1999)
    └── 00000000000000002000.log  (segment 3: offsets 2000+, active)
                                              ^
                                              └── new messages appended here

================================================================================
2. OS PAGE CACHE UTILIZATION
================================================================================

WHAT IS PAGE CACHE?
    - OS uses free RAM to cache recently accessed disk data
    - Automatic, managed by operating system kernel
    - Read from disk once, subsequent reads from RAM

WITHOUT PAGE CACHE (Traditional approach):

    Application                    Disk
        |                           |
        |-- read data ------------>|
        |<-- data from disk -------|  (slow, every time)
        |                           |

WITH PAGE CACHE (Kafka approach):

    Application         Page Cache (RAM)         Disk
        |                     |                    |
        |-- read data ------->|                    |
        |                     |-- not in cache --->|
        |                     |<-- load to cache --|
        |<-- data from cache -|                    |
        |                     |                    |
        |-- read same data -->|                    |
        |<-- from cache ------|  (fast, no disk!)  |

KAFKA'S STRATEGY:
    - Kafka doesn't maintain its own cache
    - Relies entirely on OS page cache
    - JVM heap stays small (no GC pauses)
    - More RAM = bigger page cache = faster Kafka

    Why this is smart:
    +---------------------------------+----------------------------------+
    | Application-level Cache         | OS Page Cache (Kafka's approach) |
    +---------------------------------+----------------------------------+
    | Data in JVM heap                | Data in kernel memory            |
    | Subject to GC pauses            | No GC, managed by OS             |
    | Lost on app restart             | Survives app restart             |
    | Duplicates OS cache (wasteful)  | Single copy of data              |
    | Manual management needed        | Automatic, optimized by OS       |
    +---------------------------------+----------------------------------+

PRACTICAL IMPLICATION:
    - Give Kafka server minimal heap (4-8GB)
    - Leave rest of RAM for OS page cache
    - 32GB RAM server: 6GB heap + 26GB page cache

================================================================================
3. ZERO-COPY TRANSFER
================================================================================

TRADITIONAL DATA TRANSFER (4 copies, 4 context switches):

    User wants to send file over network:

    Step 1: Disk → Kernel Buffer (DMA copy)
    Step 2: Kernel Buffer → Application Buffer (CPU copy, context switch)
    Step 3: Application Buffer → Socket Buffer (CPU copy, context switch)
    Step 4: Socket Buffer → NIC (DMA copy)

    Disk                                                    Network
     |                                                         |
     |--[DMA]--> Kernel -----> App -----> Kernel --[DMA]----> NIC
                Buffer       Buffer      Socket
                  |            |           |
                  +--- CPU ----+--- CPU ---+
                       copy         copy

    Problems:
    - 4 data copies (2 unnecessary)
    - 4 context switches (user ↔ kernel)
    - CPU busy copying data
    - High memory bandwidth usage

ZERO-COPY TRANSFER (2 copies, 2 context switches):

    Using sendfile() system call:

    Step 1: Disk → Kernel Buffer (DMA copy)
    Step 2: Kernel Buffer → NIC (DMA copy, with descriptor)

    Disk                                                    Network
     |                                                         |
     |--[DMA]--> Kernel Buffer --------[DMA]----------------> NIC
                      |
                      +-- no CPU copy, no app buffer!

    Benefits:
    - 2 copies instead of 4
    - 2 context switches instead of 4
    - CPU not involved in copying
    - ~65% reduction in CPU usage

KAFKA'S IMPLEMENTATION:
    - Uses Java's FileChannel.transferTo()
    - Maps to sendfile() on Linux
    - Data flows directly: Disk → Network
    - Consumer reads don't touch application memory

    // Kafka's code path (simplified)
    fileChannel.transferTo(position, count, socketChannel);
    // Data goes disk → network without touching JVM heap

WHEN ZERO-COPY IS USED:
    - Consumer fetching messages
    - Data already in page cache (even faster)
    - Not used for: compression, SSL/TLS (data needs processing)

================================================================================
4. BATCHING OF MESSAGES
================================================================================

WITHOUT BATCHING:

    Producer sends 1000 messages:

    [msg1] → network → broker → disk
    [msg2] → network → broker → disk
    [msg3] → network → broker → disk
    ...
    [msg1000] → network → broker → disk

    Problems:
    - 1000 network round trips
    - 1000 disk writes
    - High overhead per message

WITH BATCHING (Kafka's approach):

    Producer collects messages, sends as batch:

    [msg1, msg2, msg3, ... msg1000] → network → broker → disk

    Benefits:
    - 1 network round trip
    - 1 disk write
    - Overhead amortized across batch

BATCHING HAPPENS AT MULTIPLE LEVELS:

1. Producer Batching:
   - Collects messages for same partition
   - Sends when batch.size reached OR linger.ms expires

   Config:
       batch.size=16384        # 16KB batch
       linger.ms=5             # wait up to 5ms for more messages

2. Broker Batching:
   - Writes multiple messages in single I/O operation
   - Flushes based on configuration

3. Consumer Batching:
   - Fetches multiple messages per request
   - Configurable fetch size

   Config:
       fetch.min.bytes=1       # min data before responding
       fetch.max.wait.ms=500   # max wait time

BATCHING + COMPRESSION:

    Individual messages:
    [msg1:100B] [msg2:100B] [msg3:100B] = 300B + 3x overhead

    Batched + Compressed:
    [msg1 + msg2 + msg3] → compress → [compressed:150B] = 150B + 1x overhead

    Compression types: gzip, snappy, lz4, zstd

    Config:
        compression.type=lz4    # good balance of speed/ratio

================================================================================
PERFORMANCE SUMMARY
================================================================================

+---------------------+------------------+----------------------------------+
| Technique           | What it solves   | Impact                           |
+---------------------+------------------+----------------------------------+
| Sequential I/O      | Disk seek time   | 100MB/s vs 100 IOPS              |
+---------------------+------------------+----------------------------------+
| OS Page Cache       | Repeated reads   | RAM speed for hot data           |
+---------------------+------------------+----------------------------------+
| Zero-Copy           | CPU overhead     | 65% less CPU, no extra copies    |
+---------------------+------------------+----------------------------------+
| Batching            | Per-message      | Amortize overhead across batch   |
|                     | overhead         |                                  |
+---------------------+------------------+----------------------------------+

COMBINED EFFECT:
    - Single broker can handle 100K-200K messages/second
    - Throughput can exceed 100 MB/s per broker
    - Latency in low milliseconds
    - Scales linearly by adding brokers

================================================================================
